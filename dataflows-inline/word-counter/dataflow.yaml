apiVersion: 0.5.0
meta:
  name: word-counter
  version: 0.1.0
  namespace: examples

config:
  # Data format converter for reading & writing to topics.
  #   - json, raw
  converter: json

  # Consumers need to know where to start reading when the project is first started
  #   - {position: Begining, value: 0}
  #   - {position: End, value: 2}
  #   - {position: Offset, value: 23}
  consumer:
    default_starting_offset:
      value: 0
      position: End

types:
  # Schema for the input topic
  sentence:
    type: string

  # Schema for the aggregate logic and output topic
  word-count:
    type: object
    properties:
      word:
        type: string
      count:
        type: u32

  # Schema for the output topic
  top-words:
    type: list
    items:
      type: word-count

topics:
  # topic definitions, schema, add converters that are different from config.converter.
  sentence:
    name: sentence
    schema:
      value:
        type: string
        converter: raw
  most-used-words:
    name: most-used-words
    schema:
      value:
        type: top-words

services:
  # Service definition the input and output topics, and the transformations.
  word-processing-window:
    sources:
      - type: topic
        id: sentence

    states:
      count-per-word:
        type: keyed-state
        properties:
          key:
            type: string
          value:
            type: arrow-row
            properties:
              count:
                type: u32

    transforms:
      # Split the sentence into words
      - operator: flat-map
        run: |
          fn split_sequence(sentence: String) -> Result<Vec<String>> {
            Ok(sentence.split_whitespace().map(|word| word.chars().filter(|c| c.is_alphanumeric()).collect::<String>()).filter(|word| !word.is_empty()).collect())
          }
    window:
      tumbling:
        duration: 20s

      assign-timestamp:
        # Instruct the engine to apply the timestamp from the event metadata for the watermark operator
        run: |
          fn assign_event_timestamp(_value: String, event_time: i64) -> Result<i64> {
            Ok(event_time)
          }

      partition:
        # Assign a partition key to divide the data set for the update operation
        assign-key:
          run: |
            fn assign_word_key(word: String) -> Result<String> {
              Ok(word.to_lowercase().chars().filter(|c| c.is_alphanumeric()).collect())
            }

        update-state:
          # Retrieve state by key and increment by 1.
          run: |
            fn increment_word_count(_word: String) -> Result<()> {
              let mut state = count_per_word();
              state.count += 1;
              state.update();
              Ok(())
            }

      flush:
        # Read the full state and compute the top 3 words sorted by count.
        run: |
          fn compute_most_used_words() -> Result<TopWords> {
            let word_counts = count_per_word();

            let top3 = word_counts.sql("select * from count_per_word order by count desc limit 3")?;
            let rows = top3.rows()?;
            let columns = top3.schema(["_key","count"])?;

            let mut top_words = vec![];
            match &columns[..] {
              [key,value] => {
                  while rows.next() {
                    let word = rows.str(&key)?;
                    let count = rows.u32(&value)?;
                    let word_count = WordCount { word, count };
                    top_words.push(word_count);
                  }

              },
                _ => return Err(anyhow::anyhow!("unexpected schema")),
            }

            Ok(top_words)
          }

    sinks:
      - type: topic
        id: most-used-words
